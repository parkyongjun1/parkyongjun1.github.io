---
title: Paper Review. Unified Vision Language Pre-Training for Image Captioning and VQA@AAAI’ 2020
author: YongJun Park
date: 2020-12-01 18:00:00 +0900
categories: [Paper Reviews, CV]
tags: [Image Captioning, Visual Question Answering]
math: true
pin: True
---

- [Paper link](https://arxiv.org/abs/1909.11059)


## **Abstract**
<img src="/assets/papers/Unified Vision_Language/7.png" width='800'>
<img src="/assets/papers/Unified Vision_Language/8.png" width='800'>

## **Introduction**
<img src="/assets/papers/Unified Vision_Language/4.png" width='800'>
<img src="/assets/papers/Unified Vision_Language/5.png" width='800'>

## **Related Work**
<img src="/assets/papers/Unified Vision_Language/10.png" width='800'>
<img src="/assets/papers/Unified Vision_Language/11.png" width='800'>

## **Vision Language Pre training**
<img src="/assets/papers/Unified Vision_Language/13.png" width='800'>
<img src="/assets/papers/Unified Vision_Language/14.png" width='800'>
<img src="/assets/papers/Unified Vision_Language/15.png" width='800'>
<img src="/assets/papers/Unified Vision_Language/16.png" width='800'>
<img src="/assets/papers/Unified Vision_Language/17.png" width='800'>
<img src="/assets/papers/Unified Vision_Language/18.png" width='800'>
<img src="/assets/papers/Unified Vision_Language/19.png" width='800'>
<img src="/assets/papers/Unified Vision_Language/20.png" width='800'>
<img src="/assets/papers/Unified Vision_Language/21.png" width='800'>
<img src="/assets/papers/Unified Vision_Language/22.png" width='800'>

## **Experiments**
<img src="/assets/papers/Unified Vision_Language/24.png" width='800'>
<img src="/assets/papers/Unified Vision_Language/25.png" width='800'>
<img src="/assets/papers/Unified Vision_Language/26.png" width='800'>
<img src="/assets/papers/Unified Vision_Language/27.png" width='800'>
<img src="/assets/papers/Unified Vision_Language/28.png" width='800'>
<img src="/assets/papers/Unified Vision_Language/29.png" width='800'>


## **Conclusions & Reviews**
- Image captioning과 VQA tasks들에 적용할 수 있는 Unified VLP model을 선보임.

- 대부분의 down stream tasks에서 SOTA 성능을 보임.

- encoder decoder를 분리하지 않고 하나의 통합된 모델로 사용하는 점이 흥미로움.


## **Reference**
